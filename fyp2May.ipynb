{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import json\n",
    "import pymongo\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (r'/home/muhammadsiraj/Downloads/Books/Natural Language Processing with Python.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_book_name = doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural Language Processing with Python'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_book_name['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = doc.getToC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'Table of Contents', 7],\n",
       " [1, 'Preface', 11],\n",
       " [2, 'Audience', 12],\n",
       " [2, 'Emphasis', 12],\n",
       " [2, 'What You Will Learn', 13],\n",
       " [2, 'Organization', 13],\n",
       " [2, 'Why Python?', 14],\n",
       " [2, 'Software Requirements', 15],\n",
       " [2, 'Natural Language Toolkit (NLTK)', 16],\n",
       " [2, 'For Instructors', 17],\n",
       " [2, 'Conventions Used in This Book', 19],\n",
       " [2, 'Using Code Examples', 19],\n",
       " [2, 'Safari® Books Online', 20],\n",
       " [2, 'How to Contact Us', 20],\n",
       " [2, 'Acknowledgments', 21],\n",
       " [2, 'Royalties', 21],\n",
       " [1, 'Chapter\\xa01.\\xa0Language Processing and Python', 23],\n",
       " [2, '1.1\\xa0 Computing with Language: Texts and Words', 23],\n",
       " [3, 'Getting Started with Python', 24],\n",
       " [3, 'Getting Started with NLTK', 25],\n",
       " [3, 'Searching Text', 26],\n",
       " [3, 'Counting Vocabulary', 29],\n",
       " [2, '1.2\\xa0 A Closer Look at Python: Texts as Lists of Words', 32],\n",
       " [3, 'Lists', 32],\n",
       " [3, 'Indexing Lists', 34],\n",
       " [3, 'Variables', 36],\n",
       " [3, 'Strings', 37],\n",
       " [2, '1.3\\xa0 Computing with Language: Simple Statistics', 38],\n",
       " [3, 'Frequency Distributions', 39],\n",
       " [3, 'Fine-Grained Selection of Words', 41],\n",
       " [3, 'Collocations and Bigrams', 42],\n",
       " [3, 'Counting Other Things', 43],\n",
       " [2, '1.4\\xa0 Back to Python: Making Decisions and Taking Control', 44],\n",
       " [3, 'Conditionals', 44],\n",
       " [3, 'Operating on Every Element', 46],\n",
       " [3, 'Nested Code Blocks', 47],\n",
       " [3, 'Looping with Conditions', 48],\n",
       " [2, '1.5\\xa0 Automatic Natural Language Understanding', 49],\n",
       " [3, 'Word Sense Disambiguation', 50],\n",
       " [3, 'Pronoun Resolution', 50],\n",
       " [3, 'Generating Language Output', 51],\n",
       " [3, 'Machine Translation', 51],\n",
       " [3, 'Spoken Dialogue Systems', 53],\n",
       " [3, 'Textual Entailment', 54],\n",
       " [3, 'Limitations of NLP', 55],\n",
       " [2, '1.6\\xa0 Summary', 55],\n",
       " [2, '1.7\\xa0 Further Reading', 56],\n",
       " [2, '1.8\\xa0 Exercises', 57],\n",
       " [1, 'Chapter\\xa02.\\xa0Accessing Text Corpora and Lexical\\n  Resources', 61],\n",
       " [2, '2.1\\xa0 Accessing Text Corpora', 61],\n",
       " [3, 'Gutenberg Corpus', 62],\n",
       " [3, 'Web and Chat Text', 64],\n",
       " [3, 'Brown Corpus', 64],\n",
       " [3, 'Reuters Corpus', 66],\n",
       " [3, 'Inaugural Address Corpus', 67],\n",
       " [3, 'Annotated Text Corpora', 68],\n",
       " [3, 'Corpora in Other Languages', 70],\n",
       " [3, 'Text Corpus Structure', 71],\n",
       " [3, 'Loading Your Own Corpus', 73],\n",
       " [2, '2.2\\xa0 Conditional Frequency Distributions', 74],\n",
       " [3, 'Conditions and Events', 74],\n",
       " [3, 'Counting Words by Genre', 74],\n",
       " [3, 'Plotting and Tabulating Distributions', 75],\n",
       " [3, 'Generating Random Text with Bigrams', 77],\n",
       " [2, '2.3\\xa0 More Python: Reusing Code', 78],\n",
       " [3, 'Creating Programs with a Text Editor', 78],\n",
       " [3, 'Functions', 79],\n",
       " [3, 'Modules', 81],\n",
       " [2, '2.4\\xa0 Lexical Resources', 81],\n",
       " [3, 'Wordlist Corpora', 82],\n",
       " [3, 'A Pronouncing Dictionary', 85],\n",
       " [3, 'Comparative Wordlists', 87],\n",
       " [3, 'Shoebox and Toolbox Lexicons', 88],\n",
       " [2, '2.5\\xa0 WordNet', 89],\n",
       " [3, 'Senses and Synonyms', 89],\n",
       " [3, 'The WordNet Hierarchy', 91],\n",
       " [3, 'More Lexical Relations', 92],\n",
       " [3, 'Semantic Similarity', 93],\n",
       " [2, '2.6\\xa0 Summary', 95],\n",
       " [2, '2.7\\xa0 Further Reading', 95],\n",
       " [2, '2.8\\xa0 Exercises', 96],\n",
       " [1, 'Chapter\\xa03.\\xa0Processing Raw Text', 101],\n",
       " [2, '3.1\\xa0 Accessing Text from the Web and from Disk', 102],\n",
       " [3, 'Electronic Books', 102],\n",
       " [3, 'Dealing with HTML', 103],\n",
       " [3, 'Processing Search Engine Results', 104],\n",
       " [3, 'Processing RSS Feeds', 105],\n",
       " [3, 'Reading Local Files', 106],\n",
       " [3, 'Extracting Text from PDF, MSWord, and Other Binary Formats', 107],\n",
       " [3, 'Capturing User Input', 107],\n",
       " [3, 'The NLP Pipeline', 108],\n",
       " [2, '3.2\\xa0 Strings: Text Processing at the Lowest Level', 109],\n",
       " [3, 'Basic Operations with Strings', 109],\n",
       " [3, 'Printing Strings', 111],\n",
       " [3, 'Accessing Individual Characters', 111],\n",
       " [3, 'Accessing Substrings', 112],\n",
       " [3, 'More Operations on Strings', 114],\n",
       " [3, 'The Difference Between Lists and Strings', 114],\n",
       " [2, '3.3\\xa0 Text Processing with Unicode', 115],\n",
       " [3, 'What Is Unicode?', 116],\n",
       " [3, 'Extracting Encoded Text from Files', 116],\n",
       " [3, 'Using Your Local Encoding in Python', 119],\n",
       " [2, '3.4\\xa0 Regular Expressions for Detecting Word Patterns', 119],\n",
       " [3, 'Using Basic Metacharacters', 120],\n",
       " [3, 'Ranges and Closures', 121],\n",
       " [2, '3.5\\xa0 Useful Applications of Regular Expressions', 124],\n",
       " [3, 'Extracting Word Pieces', 124],\n",
       " [3, 'Doing More with Word Pieces', 124],\n",
       " [3, 'Finding Word Stems', 126],\n",
       " [3, 'Searching Tokenized Text', 127],\n",
       " [2, '3.6\\xa0 Normalizing Text', 129],\n",
       " [3, 'Stemmers', 129],\n",
       " [3, 'Lemmatization', 130],\n",
       " [2, '3.7\\xa0 Regular Expressions for Tokenizing Text', 131],\n",
       " [3, 'Simple Approaches to Tokenization', 131],\n",
       " [3, 'NLTK’s Regular Expression Tokenizer', 133],\n",
       " [3, 'Further Issues with Tokenization', 133],\n",
       " [2, '3.8\\xa0 Segmentation', 134],\n",
       " [3, 'Sentence Segmentation', 134],\n",
       " [3, 'Word Segmentation', 135],\n",
       " [2, '3.9\\xa0 Formatting: From Lists to Strings', 138],\n",
       " [3, 'From Lists to Strings', 138],\n",
       " [3, 'Strings and Formats', 139],\n",
       " [3, 'Lining Things Up', 140],\n",
       " [3, 'Writing Results to a File', 142],\n",
       " [3, 'Text Wrapping', 142],\n",
       " [2, '3.10\\xa0 Summary', 143],\n",
       " [2, '3.11\\xa0 Further Reading', 144],\n",
       " [2, '3.12\\xa0 Exercises', 145],\n",
       " [1, 'Chapter\\xa04.\\xa0Writing Structured Programs', 151],\n",
       " [2, '4.1\\xa0 Back to the Basics', 152],\n",
       " [3, 'Assignment', 152],\n",
       " [3, 'Equality', 154],\n",
       " [3, 'Conditionals', 155],\n",
       " [2, '4.2\\xa0 Sequences', 155],\n",
       " [3, 'Operating on Sequence Types', 156],\n",
       " [3, 'Combining Different Sequence Types', 158],\n",
       " [3, 'Generator Expressions', 159],\n",
       " [2, '4.3\\xa0 Questions of Style', 160],\n",
       " [3, 'Python Coding Style', 160],\n",
       " [3, 'Procedural Versus Declarative Style', 161],\n",
       " [3, 'Some Legitimate Uses for Counters', 163],\n",
       " [2, '4.4\\xa0 Functions: The Foundation of Structured Programming', 164],\n",
       " [3, 'Function Inputs and Outputs', 165],\n",
       " [3, 'Parameter Passing', 166],\n",
       " [3, 'Variable Scope', 167],\n",
       " [3, 'Checking Parameter Types', 168],\n",
       " [3, 'Functional Decomposition', 169],\n",
       " [3, 'Documenting Functions', 170],\n",
       " [2, '4.5\\xa0 Doing More with Functions', 171],\n",
       " [3, 'Functions As Arguments', 171],\n",
       " [3, 'Accumulative Functions', 172],\n",
       " [3, 'Higher-Order Functions', 173],\n",
       " [3, 'Named Arguments', 174],\n",
       " [2, '4.6\\xa0 Program Development', 176],\n",
       " [3, 'Structure of a Python Module', 176],\n",
       " [3, 'Multimodule Programs', 177],\n",
       " [3, 'Sources of Error', 178],\n",
       " [3, 'Debugging Techniques', 180],\n",
       " [3, 'Defensive Programming', 181],\n",
       " [2, '4.7\\xa0 Algorithm Design', 182],\n",
       " [3, 'Recursion', 182],\n",
       " [3, 'Space-Time Trade-offs', 185],\n",
       " [3, 'Dynamic Programming', 187],\n",
       " [2, '4.8\\xa0 A Sample of Python Libraries', 189],\n",
       " [3, 'Matplotlib', 190],\n",
       " [3, 'NetworkX', 191],\n",
       " [3, 'csv', 192],\n",
       " [3, 'NumPy', 193],\n",
       " [3, 'Other Python Libraries', 194],\n",
       " [2, '4.9\\xa0 Summary', 194],\n",
       " [2, '4.10\\xa0 Further Reading', 195],\n",
       " [2, '4.11\\xa0 Exercises', 195],\n",
       " [1, 'Chapter\\xa05.\\xa0Categorizing and Tagging Words', 201],\n",
       " [2, '5.1\\xa0 Using a Tagger', 201],\n",
       " [2, '5.2\\xa0 Tagged Corpora', 203],\n",
       " [3, 'Representing Tagged Tokens', 203],\n",
       " [3, 'Reading Tagged Corpora', 203],\n",
       " [3, 'A Simplified Part-of-Speech Tagset', 205],\n",
       " [3, 'Nouns', 206],\n",
       " [3, 'Verbs', 207],\n",
       " [3, 'Adjectives and Adverbs', 208],\n",
       " [3, 'Unsimplified Tags', 209],\n",
       " [3, 'Exploring Tagged Corpora', 209],\n",
       " [2, '5.3\\xa0 Mapping Words to Properties Using Python Dictionaries', 211],\n",
       " [3, 'Indexing Lists Versus Dictionaries', 211],\n",
       " [3, 'Dictionaries in Python', 212],\n",
       " [3, 'Defining Dictionaries', 215],\n",
       " [3, 'Default Dictionaries', 215],\n",
       " [3, 'Incrementally Updating a Dictionary', 216],\n",
       " [3, 'Complex Keys and Values', 218],\n",
       " [3, 'Inverting a Dictionary', 219],\n",
       " [2, '5.4\\xa0 Automatic Tagging', 220],\n",
       " [3, 'The Default Tagger', 220],\n",
       " [3, 'The Regular Expression Tagger', 221],\n",
       " [3, 'The Lookup Tagger', 222],\n",
       " [3, 'Evaluation', 223],\n",
       " [2, '5.5\\xa0 N-Gram Tagging', 224],\n",
       " [3, 'Unigram Tagging', 224],\n",
       " [3, 'Separating the Training and Testing Data', 225],\n",
       " [3, 'General N-Gram Tagging', 225],\n",
       " [3, 'Combining Taggers', 227],\n",
       " [3, 'Tagging Unknown Words', 228],\n",
       " [3, 'Storing Taggers', 228],\n",
       " [3, 'Performance Limitations', 228],\n",
       " [3, 'Tagging Across Sentence Boundaries', 230],\n",
       " [2, '5.6\\xa0 Transformation-Based Tagging', 230],\n",
       " [2, '5.7\\xa0 How to Determine the Category of a Word', 232],\n",
       " [3, 'Morphological Clues', 233],\n",
       " [3, 'Syntactic Clues', 233],\n",
       " [3, 'Semantic Clues', 233],\n",
       " [3, 'New Words', 233],\n",
       " [3, 'Morphology in Part-of-Speech Tagsets', 234],\n",
       " [2, '5.8\\xa0 Summary', 235],\n",
       " [2, '5.9\\xa0 Further Reading', 236],\n",
       " [2, '5.10\\xa0 Exercises', 237],\n",
       " [1, 'Chapter\\xa06.\\xa0Learning to Classify Text', 243],\n",
       " [2, '6.1\\xa0 Supervised Classification', 243],\n",
       " [3, 'Gender Identification', 244],\n",
       " [3, 'Choosing the Right Features', 246],\n",
       " [3, 'Document Classification', 249],\n",
       " [3, 'Part-of-Speech Tagging', 251],\n",
       " [3, 'Exploiting Context', 252],\n",
       " [3, 'Sequence Classification', 253],\n",
       " [3, 'Other Methods for Sequence Classification', 255],\n",
       " [2, '6.2\\xa0 Further Examples of Supervised Classification', 255],\n",
       " [3, 'Sentence Segmentation', 255],\n",
       " [3, 'Identifying Dialogue Act Types', 257],\n",
       " [3, 'Recognizing Textual Entailment', 257],\n",
       " [3, 'Scaling Up to Large Datasets', 259],\n",
       " [2, '6.3\\xa0 Evaluation', 259],\n",
       " [3, 'The Test Set', 259],\n",
       " [3, 'Accuracy', 261],\n",
       " [3, 'Precision and Recall', 261],\n",
       " [3, 'Confusion Matrices', 262],\n",
       " [3, 'Cross-Validation', 263],\n",
       " [2, '6.4\\xa0 Decision Trees', 264],\n",
       " [3, 'Entropy and Information Gain', 265],\n",
       " [2, '6.5\\xa0 Naive Bayes Classifiers', 267],\n",
       " [3, 'Underlying Probabilistic Model', 269],\n",
       " [3, 'Zero Counts and Smoothing', 270],\n",
       " [3, 'Non-Binary Features', 271],\n",
       " [3, 'The Naivete of Independence', 271],\n",
       " [3, 'The Cause of Double-Counting', 272],\n",
       " [2, '6.6\\xa0 Maximum Entropy Classifiers', 272],\n",
       " [3, 'The Maximum Entropy Model', 273],\n",
       " [3, 'Maximizing Entropy', 274],\n",
       " [3, 'Generative Versus Conditional Classifiers', 276],\n",
       " [2, '6.7\\xa0 Modeling Linguistic Patterns', 276],\n",
       " [3, 'What Do Models Tell Us?', 277],\n",
       " [2, '6.8\\xa0 Summary', 278],\n",
       " [2, '6.9\\xa0 Further Reading', 278],\n",
       " [2, '6.10\\xa0 Exercises', 279],\n",
       " [1, 'Chapter\\xa07.\\xa0Extracting Information from Text', 283],\n",
       " [2, '7.1\\xa0 Information Extraction', 283],\n",
       " [3, 'Information Extraction Architecture', 285],\n",
       " [2, '7.2\\xa0 Chunking', 286],\n",
       " [3, 'Noun Phrase Chunking', 286],\n",
       " [3, 'Tag Patterns', 288],\n",
       " [3, 'Chunking with Regular Expressions', 288],\n",
       " [3, 'Exploring Text Corpora', 289],\n",
       " [3, 'Chinking', 290],\n",
       " [3, 'Representing Chunks: Tags Versus Trees', 291],\n",
       " [2, '7.3\\xa0 Developing and Evaluating Chunkers', 292],\n",
       " [3, 'Reading IOB Format and the CoNLL-2000 Chunking Corpus', 292],\n",
       " [3, 'Simple Evaluation and Baselines', 294],\n",
       " [3, 'Training Classifier-Based Chunkers', 296],\n",
       " [2, '7.4\\xa0 Recursion in Linguistic Structure', 299],\n",
       " [3, 'Building Nested Structure with Cascaded Chunkers', 299],\n",
       " [3, 'Trees', 301],\n",
       " [3, 'Tree Traversal', 302],\n",
       " [2, '7.5\\xa0 Named Entity Recognition', 303],\n",
       " [2, '7.6\\xa0 Relation Extraction', 306],\n",
       " [2, '7.7\\xa0 Summary', 307],\n",
       " [2, '7.8\\xa0 Further Reading', 308],\n",
       " [2, '7.9\\xa0 Exercises', 308],\n",
       " [1, 'Chapter\\xa08.\\xa0Analyzing Sentence Structure', 313],\n",
       " [2, '8.1\\xa0 Some Grammatical Dilemmas', 314],\n",
       " [3, 'Linguistic Data and Unlimited Possibilities', 314],\n",
       " [3, 'Ubiquitous Ambiguity', 315],\n",
       " [2, '8.2\\xa0 What’s the Use of Syntax?', 317],\n",
       " [3, 'Beyond n-grams', 317],\n",
       " [2, '8.3\\xa0 Context-Free Grammar', 320],\n",
       " [3, 'A Simple Grammar', 320],\n",
       " [3, 'Writing Your Own Grammars', 322],\n",
       " [3, 'Recursion in Syntactic Structure', 323],\n",
       " [2, '8.4\\xa0 Parsing with Context-Free Grammar', 324],\n",
       " [3, 'Recursive Descent Parsing', 325],\n",
       " [3, 'Shift-Reduce Parsing', 326],\n",
       " [3, 'The Left-Corner Parser', 328],\n",
       " [3, 'Well-Formed Substring Tables', 329],\n",
       " [2, '8.5\\xa0 Dependencies and Dependency Grammar', 332],\n",
       " [3, 'Valency and the Lexicon', 334],\n",
       " [3, 'Scaling Up', 336],\n",
       " [2, '8.6\\xa0 Grammar Development', 337],\n",
       " [3, 'Treebanks and Grammars', 337],\n",
       " [3, 'Pernicious Ambiguity', 339],\n",
       " [3, 'Weighted Grammar', 340],\n",
       " [2, '8.7\\xa0 Summary', 343],\n",
       " [2, '8.8\\xa0 Further Reading', 344],\n",
       " [2, '8.9\\xa0 Exercises', 344],\n",
       " [1, 'Chapter\\xa09.\\xa0Building Feature-Based Grammars', 349],\n",
       " [2, '9.1\\xa0 Grammatical Features', 349],\n",
       " [3, 'Syntactic Agreement', 351],\n",
       " [3, 'Using Attributes and Constraints', 353],\n",
       " [3, 'Terminology', 357],\n",
       " [2, '9.2\\xa0 Processing Feature Structures', 359],\n",
       " [3, 'Subsumption and Unification', 363],\n",
       " [2, '9.3\\xa0 Extending a Feature-Based Grammar', 366],\n",
       " [3, 'Subcategorization', 366],\n",
       " [3, 'Heads Revisited', 369],\n",
       " [3, 'Auxiliary Verbs and Inversion', 370],\n",
       " [3, 'Unbounded Dependency Constructions', 371],\n",
       " [3, 'Case and Gender in German', 375],\n",
       " [2, '9.4\\xa0 Summary', 378],\n",
       " [2, '9.5\\xa0 Further Reading', 379],\n",
       " [2, '9.6\\xa0 Exercises', 380],\n",
       " [1, 'Chapter\\xa010.\\xa0Analyzing the Meaning of Sentences', 383],\n",
       " [2, '10.1\\xa0 Natural Language Understanding', 383],\n",
       " [3, 'Querying a Database', 383],\n",
       " [3, 'Natural Language, Semantics, and Logic', 387],\n",
       " [2, '10.2\\xa0 Propositional Logic', 390],\n",
       " [2, '10.3\\xa0 First-Order Logic', 394],\n",
       " [3, 'Syntax', 394],\n",
       " [3, 'First-Order Theorem Proving', 397],\n",
       " [3, 'Summarizing the Language of First-Order Logic', 398],\n",
       " [3, 'Truth in Model', 399],\n",
       " [3, 'Individual Variables and Assignments', 400],\n",
       " [3, 'Quantification', 402],\n",
       " [3, 'Quantifier Scope Ambiguity', 403],\n",
       " [3, 'Model Building', 405],\n",
       " [2, '10.4\\xa0 The Semantics of English Sentences', 407],\n",
       " [3, 'Compositional Semantics in Feature-Based Grammar', 407],\n",
       " [3, 'The λ-Calculus', 408],\n",
       " [3, 'Quantified NPs', 412],\n",
       " [3, 'Transitive Verbs', 413],\n",
       " [3, 'Quantifier Ambiguity Revisited', 416],\n",
       " [2, '10.5\\xa0 Discourse Semantics', 419],\n",
       " [3, 'Discourse Representation Theory', 419],\n",
       " [3, 'Discourse Processing', 422],\n",
       " [2, '10.6\\xa0 Summary', 424],\n",
       " [2, '10.7\\xa0 Further Reading', 425],\n",
       " [2, '10.8\\xa0 Exercises', 426],\n",
       " [1, 'Chapter\\xa011.\\xa0Managing Linguistic Data', 429],\n",
       " [2, '11.1\\xa0 Corpus Structure: A Case Study', 429],\n",
       " [3, 'The Structure of TIMIT', 429],\n",
       " [3, 'Notable Design Features', 431],\n",
       " [3, 'Fundamental Data Types', 433],\n",
       " [2, '11.2\\xa0 The Life Cycle of a Corpus', 434],\n",
       " [3, 'Three Corpus Creation Scenarios', 434],\n",
       " [3, 'Quality Control', 435],\n",
       " [3, 'Curation Versus Evolution', 436],\n",
       " [2, '11.3\\xa0 Acquiring Data', 438],\n",
       " [3, 'Obtaining Data from the Web', 438],\n",
       " [3, 'Obtaining Data from Word Processor Files', 438],\n",
       " [3, 'Obtaining Data from Spreadsheets and Databases', 440],\n",
       " [3, 'Converting Data Formats', 441],\n",
       " [3, 'Deciding Which Layers of Annotation to Include', 442],\n",
       " [3, 'Standards and Tools', 443],\n",
       " [3, 'Special Considerations When Working with Endangered Languages', 444],\n",
       " [2, '11.4\\xa0 Working with XML', 447],\n",
       " [3, 'Using XML for Linguistic Structures', 447],\n",
       " [3, 'The Role of XML', 448],\n",
       " [3, 'The ElementTree Interface', 449],\n",
       " [3, 'Using ElementTree for Accessing Toolbox Data', 451],\n",
       " [3, 'Formatting Entries', 452],\n",
       " [2, '11.5\\xa0 Working with Toolbox Data', 453],\n",
       " [3, 'Adding a Field to Each Entry', 453],\n",
       " [3, 'Validating a Toolbox Lexicon', 454],\n",
       " [2, '11.6\\xa0 Describing Language Resources Using OLAC Metadata', 457],\n",
       " [3, 'What Is Metadata?', 457],\n",
       " [3, 'OLAC: Open Language Archives Community', 457],\n",
       " [2, '11.7\\xa0 Summary', 459],\n",
       " [2, '11.8\\xa0 Further Reading', 459],\n",
       " [2, '11.9\\xa0 Exercises', 460],\n",
       " [1, 'Afterword: The Language Challenge', 463],\n",
       " [2, 'Language Processing Versus Symbol Processing', 464],\n",
       " [2, 'Contemporary Philosophical Divides', 465],\n",
       " [2, 'NLTK Roadmap', 466],\n",
       " [2, 'Envoi...', 469],\n",
       " [1, 'Bibliography', 471],\n",
       " [1, 'NLTK Index', 481],\n",
       " [1, 'General Index', 485]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mD = {}\n",
    "for i in toc:\n",
    "    d={}\n",
    "    d[\"bn\"]=get_book_name['title']\n",
    "    d[\"title\"]=i[1]\n",
    "    d[\"Pgno\"]=i[2]\n",
    "    client = MongoClient()\n",
    "    client = MongoClient('localhost',27017)\n",
    "    db = client.FYP\n",
    "    collection = db['CRYPTO'] #yahan book ka nam aae ga jis bhe book ko extract krwaya ha oska collection bane ga\n",
    "    collection.insert_one(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
