{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (r'/home/muhammadsiraj/Downloads/Books/Natural Language Processing with Python.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'PDF 1.4',\n",
       " 'title': 'Natural Language Processing with Python',\n",
       " 'author': 'Steven Bird',\n",
       " 'subject': None,\n",
       " 'keywords': None,\n",
       " 'creator': 'XSL Formatter V4.3 R1 (4,3,2008,0424) for Linux',\n",
       " 'producer': 'Antenna House PDF Output Library 2.6.0 (Linux)',\n",
       " 'creationDate': \"D:20090611092502-05'00'\",\n",
       " 'modDate': \"D:20090611132929-04'00'\",\n",
       " 'encryption': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_book_name = doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural Language Processing with Python'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_book_name['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = doc.getToC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'Table of Contents', 7],\n",
       " [1, 'Preface', 11],\n",
       " [2, 'Audience', 12],\n",
       " [2, 'Emphasis', 12],\n",
       " [2, 'What You Will Learn', 13],\n",
       " [2, 'Organization', 13],\n",
       " [2, 'Why Python?', 14],\n",
       " [2, 'Software Requirements', 15],\n",
       " [2, 'Natural Language Toolkit (NLTK)', 16],\n",
       " [2, 'For Instructors', 17],\n",
       " [2, 'Conventions Used in This Book', 19],\n",
       " [2, 'Using Code Examples', 19],\n",
       " [2, 'Safari® Books Online', 20],\n",
       " [2, 'How to Contact Us', 20],\n",
       " [2, 'Acknowledgments', 21],\n",
       " [2, 'Royalties', 21],\n",
       " [1, 'Chapter\\xa01.\\xa0Language Processing and Python', 23],\n",
       " [2, '1.1\\xa0 Computing with Language: Texts and Words', 23],\n",
       " [3, 'Getting Started with Python', 24],\n",
       " [3, 'Getting Started with NLTK', 25],\n",
       " [3, 'Searching Text', 26],\n",
       " [3, 'Counting Vocabulary', 29],\n",
       " [2, '1.2\\xa0 A Closer Look at Python: Texts as Lists of Words', 32],\n",
       " [3, 'Lists', 32],\n",
       " [3, 'Indexing Lists', 34],\n",
       " [3, 'Variables', 36],\n",
       " [3, 'Strings', 37],\n",
       " [2, '1.3\\xa0 Computing with Language: Simple Statistics', 38],\n",
       " [3, 'Frequency Distributions', 39],\n",
       " [3, 'Fine-Grained Selection of Words', 41],\n",
       " [3, 'Collocations and Bigrams', 42],\n",
       " [3, 'Counting Other Things', 43],\n",
       " [2, '1.4\\xa0 Back to Python: Making Decisions and Taking Control', 44],\n",
       " [3, 'Conditionals', 44],\n",
       " [3, 'Operating on Every Element', 46],\n",
       " [3, 'Nested Code Blocks', 47],\n",
       " [3, 'Looping with Conditions', 48],\n",
       " [2, '1.5\\xa0 Automatic Natural Language Understanding', 49],\n",
       " [3, 'Word Sense Disambiguation', 50],\n",
       " [3, 'Pronoun Resolution', 50],\n",
       " [3, 'Generating Language Output', 51],\n",
       " [3, 'Machine Translation', 51],\n",
       " [3, 'Spoken Dialogue Systems', 53],\n",
       " [3, 'Textual Entailment', 54],\n",
       " [3, 'Limitations of NLP', 55],\n",
       " [2, '1.6\\xa0 Summary', 55],\n",
       " [2, '1.7\\xa0 Further Reading', 56],\n",
       " [2, '1.8\\xa0 Exercises', 57],\n",
       " [1, 'Chapter\\xa02.\\xa0Accessing Text Corpora and Lexical\\n  Resources', 61],\n",
       " [2, '2.1\\xa0 Accessing Text Corpora', 61],\n",
       " [3, 'Gutenberg Corpus', 62],\n",
       " [3, 'Web and Chat Text', 64],\n",
       " [3, 'Brown Corpus', 64],\n",
       " [3, 'Reuters Corpus', 66],\n",
       " [3, 'Inaugural Address Corpus', 67],\n",
       " [3, 'Annotated Text Corpora', 68],\n",
       " [3, 'Corpora in Other Languages', 70],\n",
       " [3, 'Text Corpus Structure', 71],\n",
       " [3, 'Loading Your Own Corpus', 73],\n",
       " [2, '2.2\\xa0 Conditional Frequency Distributions', 74],\n",
       " [3, 'Conditions and Events', 74],\n",
       " [3, 'Counting Words by Genre', 74],\n",
       " [3, 'Plotting and Tabulating Distributions', 75],\n",
       " [3, 'Generating Random Text with Bigrams', 77],\n",
       " [2, '2.3\\xa0 More Python: Reusing Code', 78],\n",
       " [3, 'Creating Programs with a Text Editor', 78],\n",
       " [3, 'Functions', 79],\n",
       " [3, 'Modules', 81],\n",
       " [2, '2.4\\xa0 Lexical Resources', 81],\n",
       " [3, 'Wordlist Corpora', 82],\n",
       " [3, 'A Pronouncing Dictionary', 85],\n",
       " [3, 'Comparative Wordlists', 87],\n",
       " [3, 'Shoebox and Toolbox Lexicons', 88],\n",
       " [2, '2.5\\xa0 WordNet', 89],\n",
       " [3, 'Senses and Synonyms', 89],\n",
       " [3, 'The WordNet Hierarchy', 91],\n",
       " [3, 'More Lexical Relations', 92],\n",
       " [3, 'Semantic Similarity', 93],\n",
       " [2, '2.6\\xa0 Summary', 95],\n",
       " [2, '2.7\\xa0 Further Reading', 95],\n",
       " [2, '2.8\\xa0 Exercises', 96],\n",
       " [1, 'Chapter\\xa03.\\xa0Processing Raw Text', 101],\n",
       " [2, '3.1\\xa0 Accessing Text from the Web and from Disk', 102],\n",
       " [3, 'Electronic Books', 102],\n",
       " [3, 'Dealing with HTML', 103],\n",
       " [3, 'Processing Search Engine Results', 104],\n",
       " [3, 'Processing RSS Feeds', 105],\n",
       " [3, 'Reading Local Files', 106],\n",
       " [3, 'Extracting Text from PDF, MSWord, and Other Binary Formats', 107],\n",
       " [3, 'Capturing User Input', 107],\n",
       " [3, 'The NLP Pipeline', 108],\n",
       " [2, '3.2\\xa0 Strings: Text Processing at the Lowest Level', 109],\n",
       " [3, 'Basic Operations with Strings', 109],\n",
       " [3, 'Printing Strings', 111],\n",
       " [3, 'Accessing Individual Characters', 111],\n",
       " [3, 'Accessing Substrings', 112],\n",
       " [3, 'More Operations on Strings', 114],\n",
       " [3, 'The Difference Between Lists and Strings', 114],\n",
       " [2, '3.3\\xa0 Text Processing with Unicode', 115],\n",
       " [3, 'What Is Unicode?', 116],\n",
       " [3, 'Extracting Encoded Text from Files', 116],\n",
       " [3, 'Using Your Local Encoding in Python', 119],\n",
       " [2, '3.4\\xa0 Regular Expressions for Detecting Word Patterns', 119],\n",
       " [3, 'Using Basic Metacharacters', 120],\n",
       " [3, 'Ranges and Closures', 121],\n",
       " [2, '3.5\\xa0 Useful Applications of Regular Expressions', 124],\n",
       " [3, 'Extracting Word Pieces', 124],\n",
       " [3, 'Doing More with Word Pieces', 124],\n",
       " [3, 'Finding Word Stems', 126],\n",
       " [3, 'Searching Tokenized Text', 127],\n",
       " [2, '3.6\\xa0 Normalizing Text', 129],\n",
       " [3, 'Stemmers', 129],\n",
       " [3, 'Lemmatization', 130],\n",
       " [2, '3.7\\xa0 Regular Expressions for Tokenizing Text', 131],\n",
       " [3, 'Simple Approaches to Tokenization', 131],\n",
       " [3, 'NLTK’s Regular Expression Tokenizer', 133],\n",
       " [3, 'Further Issues with Tokenization', 133],\n",
       " [2, '3.8\\xa0 Segmentation', 134],\n",
       " [3, 'Sentence Segmentation', 134],\n",
       " [3, 'Word Segmentation', 135],\n",
       " [2, '3.9\\xa0 Formatting: From Lists to Strings', 138],\n",
       " [3, 'From Lists to Strings', 138],\n",
       " [3, 'Strings and Formats', 139],\n",
       " [3, 'Lining Things Up', 140],\n",
       " [3, 'Writing Results to a File', 142],\n",
       " [3, 'Text Wrapping', 142],\n",
       " [2, '3.10\\xa0 Summary', 143],\n",
       " [2, '3.11\\xa0 Further Reading', 144],\n",
       " [2, '3.12\\xa0 Exercises', 145],\n",
       " [1, 'Chapter\\xa04.\\xa0Writing Structured Programs', 151],\n",
       " [2, '4.1\\xa0 Back to the Basics', 152],\n",
       " [3, 'Assignment', 152],\n",
       " [3, 'Equality', 154],\n",
       " [3, 'Conditionals', 155],\n",
       " [2, '4.2\\xa0 Sequences', 155],\n",
       " [3, 'Operating on Sequence Types', 156],\n",
       " [3, 'Combining Different Sequence Types', 158],\n",
       " [3, 'Generator Expressions', 159],\n",
       " [2, '4.3\\xa0 Questions of Style', 160],\n",
       " [3, 'Python Coding Style', 160],\n",
       " [3, 'Procedural Versus Declarative Style', 161],\n",
       " [3, 'Some Legitimate Uses for Counters', 163],\n",
       " [2, '4.4\\xa0 Functions: The Foundation of Structured Programming', 164],\n",
       " [3, 'Function Inputs and Outputs', 165],\n",
       " [3, 'Parameter Passing', 166],\n",
       " [3, 'Variable Scope', 167],\n",
       " [3, 'Checking Parameter Types', 168],\n",
       " [3, 'Functional Decomposition', 169],\n",
       " [3, 'Documenting Functions', 170],\n",
       " [2, '4.5\\xa0 Doing More with Functions', 171],\n",
       " [3, 'Functions As Arguments', 171],\n",
       " [3, 'Accumulative Functions', 172],\n",
       " [3, 'Higher-Order Functions', 173],\n",
       " [3, 'Named Arguments', 174],\n",
       " [2, '4.6\\xa0 Program Development', 176],\n",
       " [3, 'Structure of a Python Module', 176],\n",
       " [3, 'Multimodule Programs', 177],\n",
       " [3, 'Sources of Error', 178],\n",
       " [3, 'Debugging Techniques', 180],\n",
       " [3, 'Defensive Programming', 181],\n",
       " [2, '4.7\\xa0 Algorithm Design', 182],\n",
       " [3, 'Recursion', 182],\n",
       " [3, 'Space-Time Trade-offs', 185],\n",
       " [3, 'Dynamic Programming', 187],\n",
       " [2, '4.8\\xa0 A Sample of Python Libraries', 189],\n",
       " [3, 'Matplotlib', 190],\n",
       " [3, 'NetworkX', 191],\n",
       " [3, 'csv', 192],\n",
       " [3, 'NumPy', 193],\n",
       " [3, 'Other Python Libraries', 194],\n",
       " [2, '4.9\\xa0 Summary', 194],\n",
       " [2, '4.10\\xa0 Further Reading', 195],\n",
       " [2, '4.11\\xa0 Exercises', 195],\n",
       " [1, 'Chapter\\xa05.\\xa0Categorizing and Tagging Words', 201],\n",
       " [2, '5.1\\xa0 Using a Tagger', 201],\n",
       " [2, '5.2\\xa0 Tagged Corpora', 203],\n",
       " [3, 'Representing Tagged Tokens', 203],\n",
       " [3, 'Reading Tagged Corpora', 203],\n",
       " [3, 'A Simplified Part-of-Speech Tagset', 205],\n",
       " [3, 'Nouns', 206],\n",
       " [3, 'Verbs', 207],\n",
       " [3, 'Adjectives and Adverbs', 208],\n",
       " [3, 'Unsimplified Tags', 209],\n",
       " [3, 'Exploring Tagged Corpora', 209],\n",
       " [2, '5.3\\xa0 Mapping Words to Properties Using Python Dictionaries', 211],\n",
       " [3, 'Indexing Lists Versus Dictionaries', 211],\n",
       " [3, 'Dictionaries in Python', 212],\n",
       " [3, 'Defining Dictionaries', 215],\n",
       " [3, 'Default Dictionaries', 215],\n",
       " [3, 'Incrementally Updating a Dictionary', 216],\n",
       " [3, 'Complex Keys and Values', 218],\n",
       " [3, 'Inverting a Dictionary', 219],\n",
       " [2, '5.4\\xa0 Automatic Tagging', 220],\n",
       " [3, 'The Default Tagger', 220],\n",
       " [3, 'The Regular Expression Tagger', 221],\n",
       " [3, 'The Lookup Tagger', 222],\n",
       " [3, 'Evaluation', 223],\n",
       " [2, '5.5\\xa0 N-Gram Tagging', 224],\n",
       " [3, 'Unigram Tagging', 224],\n",
       " [3, 'Separating the Training and Testing Data', 225],\n",
       " [3, 'General N-Gram Tagging', 225],\n",
       " [3, 'Combining Taggers', 227],\n",
       " [3, 'Tagging Unknown Words', 228],\n",
       " [3, 'Storing Taggers', 228],\n",
       " [3, 'Performance Limitations', 228],\n",
       " [3, 'Tagging Across Sentence Boundaries', 230],\n",
       " [2, '5.6\\xa0 Transformation-Based Tagging', 230],\n",
       " [2, '5.7\\xa0 How to Determine the Category of a Word', 232],\n",
       " [3, 'Morphological Clues', 233],\n",
       " [3, 'Syntactic Clues', 233],\n",
       " [3, 'Semantic Clues', 233],\n",
       " [3, 'New Words', 233],\n",
       " [3, 'Morphology in Part-of-Speech Tagsets', 234],\n",
       " [2, '5.8\\xa0 Summary', 235],\n",
       " [2, '5.9\\xa0 Further Reading', 236],\n",
       " [2, '5.10\\xa0 Exercises', 237],\n",
       " [1, 'Chapter\\xa06.\\xa0Learning to Classify Text', 243],\n",
       " [2, '6.1\\xa0 Supervised Classification', 243],\n",
       " [3, 'Gender Identification', 244],\n",
       " [3, 'Choosing the Right Features', 246],\n",
       " [3, 'Document Classification', 249],\n",
       " [3, 'Part-of-Speech Tagging', 251],\n",
       " [3, 'Exploiting Context', 252],\n",
       " [3, 'Sequence Classification', 253],\n",
       " [3, 'Other Methods for Sequence Classification', 255],\n",
       " [2, '6.2\\xa0 Further Examples of Supervised Classification', 255],\n",
       " [3, 'Sentence Segmentation', 255],\n",
       " [3, 'Identifying Dialogue Act Types', 257],\n",
       " [3, 'Recognizing Textual Entailment', 257],\n",
       " [3, 'Scaling Up to Large Datasets', 259],\n",
       " [2, '6.3\\xa0 Evaluation', 259],\n",
       " [3, 'The Test Set', 259],\n",
       " [3, 'Accuracy', 261],\n",
       " [3, 'Precision and Recall', 261],\n",
       " [3, 'Confusion Matrices', 262],\n",
       " [3, 'Cross-Validation', 263],\n",
       " [2, '6.4\\xa0 Decision Trees', 264],\n",
       " [3, 'Entropy and Information Gain', 265],\n",
       " [2, '6.5\\xa0 Naive Bayes Classifiers', 267],\n",
       " [3, 'Underlying Probabilistic Model', 269],\n",
       " [3, 'Zero Counts and Smoothing', 270],\n",
       " [3, 'Non-Binary Features', 271],\n",
       " [3, 'The Naivete of Independence', 271],\n",
       " [3, 'The Cause of Double-Counting', 272],\n",
       " [2, '6.6\\xa0 Maximum Entropy Classifiers', 272],\n",
       " [3, 'The Maximum Entropy Model', 273],\n",
       " [3, 'Maximizing Entropy', 274],\n",
       " [3, 'Generative Versus Conditional Classifiers', 276],\n",
       " [2, '6.7\\xa0 Modeling Linguistic Patterns', 276],\n",
       " [3, 'What Do Models Tell Us?', 277],\n",
       " [2, '6.8\\xa0 Summary', 278],\n",
       " [2, '6.9\\xa0 Further Reading', 278],\n",
       " [2, '6.10\\xa0 Exercises', 279],\n",
       " [1, 'Chapter\\xa07.\\xa0Extracting Information from Text', 283],\n",
       " [2, '7.1\\xa0 Information Extraction', 283],\n",
       " [3, 'Information Extraction Architecture', 285],\n",
       " [2, '7.2\\xa0 Chunking', 286],\n",
       " [3, 'Noun Phrase Chunking', 286],\n",
       " [3, 'Tag Patterns', 288],\n",
       " [3, 'Chunking with Regular Expressions', 288],\n",
       " [3, 'Exploring Text Corpora', 289],\n",
       " [3, 'Chinking', 290],\n",
       " [3, 'Representing Chunks: Tags Versus Trees', 291],\n",
       " [2, '7.3\\xa0 Developing and Evaluating Chunkers', 292],\n",
       " [3, 'Reading IOB Format and the CoNLL-2000 Chunking Corpus', 292],\n",
       " [3, 'Simple Evaluation and Baselines', 294],\n",
       " [3, 'Training Classifier-Based Chunkers', 296],\n",
       " [2, '7.4\\xa0 Recursion in Linguistic Structure', 299],\n",
       " [3, 'Building Nested Structure with Cascaded Chunkers', 299],\n",
       " [3, 'Trees', 301],\n",
       " [3, 'Tree Traversal', 302],\n",
       " [2, '7.5\\xa0 Named Entity Recognition', 303],\n",
       " [2, '7.6\\xa0 Relation Extraction', 306],\n",
       " [2, '7.7\\xa0 Summary', 307],\n",
       " [2, '7.8\\xa0 Further Reading', 308],\n",
       " [2, '7.9\\xa0 Exercises', 308],\n",
       " [1, 'Chapter\\xa08.\\xa0Analyzing Sentence Structure', 313],\n",
       " [2, '8.1\\xa0 Some Grammatical Dilemmas', 314],\n",
       " [3, 'Linguistic Data and Unlimited Possibilities', 314],\n",
       " [3, 'Ubiquitous Ambiguity', 315],\n",
       " [2, '8.2\\xa0 What’s the Use of Syntax?', 317],\n",
       " [3, 'Beyond n-grams', 317],\n",
       " [2, '8.3\\xa0 Context-Free Grammar', 320],\n",
       " [3, 'A Simple Grammar', 320],\n",
       " [3, 'Writing Your Own Grammars', 322],\n",
       " [3, 'Recursion in Syntactic Structure', 323],\n",
       " [2, '8.4\\xa0 Parsing with Context-Free Grammar', 324],\n",
       " [3, 'Recursive Descent Parsing', 325],\n",
       " [3, 'Shift-Reduce Parsing', 326],\n",
       " [3, 'The Left-Corner Parser', 328],\n",
       " [3, 'Well-Formed Substring Tables', 329],\n",
       " [2, '8.5\\xa0 Dependencies and Dependency Grammar', 332],\n",
       " [3, 'Valency and the Lexicon', 334],\n",
       " [3, 'Scaling Up', 336],\n",
       " [2, '8.6\\xa0 Grammar Development', 337],\n",
       " [3, 'Treebanks and Grammars', 337],\n",
       " [3, 'Pernicious Ambiguity', 339],\n",
       " [3, 'Weighted Grammar', 340],\n",
       " [2, '8.7\\xa0 Summary', 343],\n",
       " [2, '8.8\\xa0 Further Reading', 344],\n",
       " [2, '8.9\\xa0 Exercises', 344],\n",
       " [1, 'Chapter\\xa09.\\xa0Building Feature-Based Grammars', 349],\n",
       " [2, '9.1\\xa0 Grammatical Features', 349],\n",
       " [3, 'Syntactic Agreement', 351],\n",
       " [3, 'Using Attributes and Constraints', 353],\n",
       " [3, 'Terminology', 357],\n",
       " [2, '9.2\\xa0 Processing Feature Structures', 359],\n",
       " [3, 'Subsumption and Unification', 363],\n",
       " [2, '9.3\\xa0 Extending a Feature-Based Grammar', 366],\n",
       " [3, 'Subcategorization', 366],\n",
       " [3, 'Heads Revisited', 369],\n",
       " [3, 'Auxiliary Verbs and Inversion', 370],\n",
       " [3, 'Unbounded Dependency Constructions', 371],\n",
       " [3, 'Case and Gender in German', 375],\n",
       " [2, '9.4\\xa0 Summary', 378],\n",
       " [2, '9.5\\xa0 Further Reading', 379],\n",
       " [2, '9.6\\xa0 Exercises', 380],\n",
       " [1, 'Chapter\\xa010.\\xa0Analyzing the Meaning of Sentences', 383],\n",
       " [2, '10.1\\xa0 Natural Language Understanding', 383],\n",
       " [3, 'Querying a Database', 383],\n",
       " [3, 'Natural Language, Semantics, and Logic', 387],\n",
       " [2, '10.2\\xa0 Propositional Logic', 390],\n",
       " [2, '10.3\\xa0 First-Order Logic', 394],\n",
       " [3, 'Syntax', 394],\n",
       " [3, 'First-Order Theorem Proving', 397],\n",
       " [3, 'Summarizing the Language of First-Order Logic', 398],\n",
       " [3, 'Truth in Model', 399],\n",
       " [3, 'Individual Variables and Assignments', 400],\n",
       " [3, 'Quantification', 402],\n",
       " [3, 'Quantifier Scope Ambiguity', 403],\n",
       " [3, 'Model Building', 405],\n",
       " [2, '10.4\\xa0 The Semantics of English Sentences', 407],\n",
       " [3, 'Compositional Semantics in Feature-Based Grammar', 407],\n",
       " [3, 'The λ-Calculus', 408],\n",
       " [3, 'Quantified NPs', 412],\n",
       " [3, 'Transitive Verbs', 413],\n",
       " [3, 'Quantifier Ambiguity Revisited', 416],\n",
       " [2, '10.5\\xa0 Discourse Semantics', 419],\n",
       " [3, 'Discourse Representation Theory', 419],\n",
       " [3, 'Discourse Processing', 422],\n",
       " [2, '10.6\\xa0 Summary', 424],\n",
       " [2, '10.7\\xa0 Further Reading', 425],\n",
       " [2, '10.8\\xa0 Exercises', 426],\n",
       " [1, 'Chapter\\xa011.\\xa0Managing Linguistic Data', 429],\n",
       " [2, '11.1\\xa0 Corpus Structure: A Case Study', 429],\n",
       " [3, 'The Structure of TIMIT', 429],\n",
       " [3, 'Notable Design Features', 431],\n",
       " [3, 'Fundamental Data Types', 433],\n",
       " [2, '11.2\\xa0 The Life Cycle of a Corpus', 434],\n",
       " [3, 'Three Corpus Creation Scenarios', 434],\n",
       " [3, 'Quality Control', 435],\n",
       " [3, 'Curation Versus Evolution', 436],\n",
       " [2, '11.3\\xa0 Acquiring Data', 438],\n",
       " [3, 'Obtaining Data from the Web', 438],\n",
       " [3, 'Obtaining Data from Word Processor Files', 438],\n",
       " [3, 'Obtaining Data from Spreadsheets and Databases', 440],\n",
       " [3, 'Converting Data Formats', 441],\n",
       " [3, 'Deciding Which Layers of Annotation to Include', 442],\n",
       " [3, 'Standards and Tools', 443],\n",
       " [3, 'Special Considerations When Working with Endangered Languages', 444],\n",
       " [2, '11.4\\xa0 Working with XML', 447],\n",
       " [3, 'Using XML for Linguistic Structures', 447],\n",
       " [3, 'The Role of XML', 448],\n",
       " [3, 'The ElementTree Interface', 449],\n",
       " [3, 'Using ElementTree for Accessing Toolbox Data', 451],\n",
       " [3, 'Formatting Entries', 452],\n",
       " [2, '11.5\\xa0 Working with Toolbox Data', 453],\n",
       " [3, 'Adding a Field to Each Entry', 453],\n",
       " [3, 'Validating a Toolbox Lexicon', 454],\n",
       " [2, '11.6\\xa0 Describing Language Resources Using OLAC Metadata', 457],\n",
       " [3, 'What Is Metadata?', 457],\n",
       " [3, 'OLAC: Open Language Archives Community', 457],\n",
       " [2, '11.7\\xa0 Summary', 459],\n",
       " [2, '11.8\\xa0 Further Reading', 459],\n",
       " [2, '11.9\\xa0 Exercises', 460],\n",
       " [1, 'Afterword: The Language Challenge', 463],\n",
       " [2, 'Language Processing Versus Symbol Processing', 464],\n",
       " [2, 'Contemporary Philosophical Divides', 465],\n",
       " [2, 'NLTK Roadmap', 466],\n",
       " [2, 'Envoi...', 469],\n",
       " [1, 'Bibliography', 471],\n",
       " [1, 'NLTK Index', 481],\n",
       " [1, 'General Index', 485]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Python3 program to Convert a  list to dictionary \n",
    "# def Convert(a): \n",
    "#     it = iter(toc) \n",
    "#     res_dct = dict(zip(it, it)) \n",
    "#     return res_dct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(Convert(toc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Table of Contents\n",
      "7\n",
      "1\n",
      "Preface\n",
      "11\n",
      "2\n",
      "Audience\n",
      "12\n",
      "2\n",
      "Emphasis\n",
      "12\n",
      "2\n",
      "What You Will Learn\n",
      "13\n",
      "2\n",
      "Organization\n",
      "13\n",
      "2\n",
      "Why Python?\n",
      "14\n",
      "2\n",
      "Software Requirements\n",
      "15\n",
      "2\n",
      "Natural Language Toolkit (NLTK)\n",
      "16\n",
      "2\n",
      "For Instructors\n",
      "17\n",
      "2\n",
      "Conventions Used in This Book\n",
      "19\n",
      "2\n",
      "Using Code Examples\n",
      "19\n",
      "2\n",
      "Safari® Books Online\n",
      "20\n",
      "2\n",
      "How to Contact Us\n",
      "20\n",
      "2\n",
      "Acknowledgments\n",
      "21\n",
      "2\n",
      "Royalties\n",
      "21\n",
      "1\n",
      "Chapter 1. Language Processing and Python\n",
      "23\n",
      "2\n",
      "1.1  Computing with Language: Texts and Words\n",
      "23\n",
      "3\n",
      "Getting Started with Python\n",
      "24\n",
      "3\n",
      "Getting Started with NLTK\n",
      "25\n",
      "3\n",
      "Searching Text\n",
      "26\n",
      "3\n",
      "Counting Vocabulary\n",
      "29\n",
      "2\n",
      "1.2  A Closer Look at Python: Texts as Lists of Words\n",
      "32\n",
      "3\n",
      "Lists\n",
      "32\n",
      "3\n",
      "Indexing Lists\n",
      "34\n",
      "3\n",
      "Variables\n",
      "36\n",
      "3\n",
      "Strings\n",
      "37\n",
      "2\n",
      "1.3  Computing with Language: Simple Statistics\n",
      "38\n",
      "3\n",
      "Frequency Distributions\n",
      "39\n",
      "3\n",
      "Fine-Grained Selection of Words\n",
      "41\n",
      "3\n",
      "Collocations and Bigrams\n",
      "42\n",
      "3\n",
      "Counting Other Things\n",
      "43\n",
      "2\n",
      "1.4  Back to Python: Making Decisions and Taking Control\n",
      "44\n",
      "3\n",
      "Conditionals\n",
      "44\n",
      "3\n",
      "Operating on Every Element\n",
      "46\n",
      "3\n",
      "Nested Code Blocks\n",
      "47\n",
      "3\n",
      "Looping with Conditions\n",
      "48\n",
      "2\n",
      "1.5  Automatic Natural Language Understanding\n",
      "49\n",
      "3\n",
      "Word Sense Disambiguation\n",
      "50\n",
      "3\n",
      "Pronoun Resolution\n",
      "50\n",
      "3\n",
      "Generating Language Output\n",
      "51\n",
      "3\n",
      "Machine Translation\n",
      "51\n",
      "3\n",
      "Spoken Dialogue Systems\n",
      "53\n",
      "3\n",
      "Textual Entailment\n",
      "54\n",
      "3\n",
      "Limitations of NLP\n",
      "55\n",
      "2\n",
      "1.6  Summary\n",
      "55\n",
      "2\n",
      "1.7  Further Reading\n",
      "56\n",
      "2\n",
      "1.8  Exercises\n",
      "57\n",
      "1\n",
      "Chapter 2. Accessing Text Corpora and Lexical\n",
      "  Resources\n",
      "61\n",
      "2\n",
      "2.1  Accessing Text Corpora\n",
      "61\n",
      "3\n",
      "Gutenberg Corpus\n",
      "62\n",
      "3\n",
      "Web and Chat Text\n",
      "64\n",
      "3\n",
      "Brown Corpus\n",
      "64\n",
      "3\n",
      "Reuters Corpus\n",
      "66\n",
      "3\n",
      "Inaugural Address Corpus\n",
      "67\n",
      "3\n",
      "Annotated Text Corpora\n",
      "68\n",
      "3\n",
      "Corpora in Other Languages\n",
      "70\n",
      "3\n",
      "Text Corpus Structure\n",
      "71\n",
      "3\n",
      "Loading Your Own Corpus\n",
      "73\n",
      "2\n",
      "2.2  Conditional Frequency Distributions\n",
      "74\n",
      "3\n",
      "Conditions and Events\n",
      "74\n",
      "3\n",
      "Counting Words by Genre\n",
      "74\n",
      "3\n",
      "Plotting and Tabulating Distributions\n",
      "75\n",
      "3\n",
      "Generating Random Text with Bigrams\n",
      "77\n",
      "2\n",
      "2.3  More Python: Reusing Code\n",
      "78\n",
      "3\n",
      "Creating Programs with a Text Editor\n",
      "78\n",
      "3\n",
      "Functions\n",
      "79\n",
      "3\n",
      "Modules\n",
      "81\n",
      "2\n",
      "2.4  Lexical Resources\n",
      "81\n",
      "3\n",
      "Wordlist Corpora\n",
      "82\n",
      "3\n",
      "A Pronouncing Dictionary\n",
      "85\n",
      "3\n",
      "Comparative Wordlists\n",
      "87\n",
      "3\n",
      "Shoebox and Toolbox Lexicons\n",
      "88\n",
      "2\n",
      "2.5  WordNet\n",
      "89\n",
      "3\n",
      "Senses and Synonyms\n",
      "89\n",
      "3\n",
      "The WordNet Hierarchy\n",
      "91\n",
      "3\n",
      "More Lexical Relations\n",
      "92\n",
      "3\n",
      "Semantic Similarity\n",
      "93\n",
      "2\n",
      "2.6  Summary\n",
      "95\n",
      "2\n",
      "2.7  Further Reading\n",
      "95\n",
      "2\n",
      "2.8  Exercises\n",
      "96\n",
      "1\n",
      "Chapter 3. Processing Raw Text\n",
      "101\n",
      "2\n",
      "3.1  Accessing Text from the Web and from Disk\n",
      "102\n",
      "3\n",
      "Electronic Books\n",
      "102\n",
      "3\n",
      "Dealing with HTML\n",
      "103\n",
      "3\n",
      "Processing Search Engine Results\n",
      "104\n",
      "3\n",
      "Processing RSS Feeds\n",
      "105\n",
      "3\n",
      "Reading Local Files\n",
      "106\n",
      "3\n",
      "Extracting Text from PDF, MSWord, and Other Binary Formats\n",
      "107\n",
      "3\n",
      "Capturing User Input\n",
      "107\n",
      "3\n",
      "The NLP Pipeline\n",
      "108\n",
      "2\n",
      "3.2  Strings: Text Processing at the Lowest Level\n",
      "109\n",
      "3\n",
      "Basic Operations with Strings\n",
      "109\n",
      "3\n",
      "Printing Strings\n",
      "111\n",
      "3\n",
      "Accessing Individual Characters\n",
      "111\n",
      "3\n",
      "Accessing Substrings\n",
      "112\n",
      "3\n",
      "More Operations on Strings\n",
      "114\n",
      "3\n",
      "The Difference Between Lists and Strings\n",
      "114\n",
      "2\n",
      "3.3  Text Processing with Unicode\n",
      "115\n",
      "3\n",
      "What Is Unicode?\n",
      "116\n",
      "3\n",
      "Extracting Encoded Text from Files\n",
      "116\n",
      "3\n",
      "Using Your Local Encoding in Python\n",
      "119\n",
      "2\n",
      "3.4  Regular Expressions for Detecting Word Patterns\n",
      "119\n",
      "3\n",
      "Using Basic Metacharacters\n",
      "120\n",
      "3\n",
      "Ranges and Closures\n",
      "121\n",
      "2\n",
      "3.5  Useful Applications of Regular Expressions\n",
      "124\n",
      "3\n",
      "Extracting Word Pieces\n",
      "124\n",
      "3\n",
      "Doing More with Word Pieces\n",
      "124\n",
      "3\n",
      "Finding Word Stems\n",
      "126\n",
      "3\n",
      "Searching Tokenized Text\n",
      "127\n",
      "2\n",
      "3.6  Normalizing Text\n",
      "129\n",
      "3\n",
      "Stemmers\n",
      "129\n",
      "3\n",
      "Lemmatization\n",
      "130\n",
      "2\n",
      "3.7  Regular Expressions for Tokenizing Text\n",
      "131\n",
      "3\n",
      "Simple Approaches to Tokenization\n",
      "131\n",
      "3\n",
      "NLTK’s Regular Expression Tokenizer\n",
      "133\n",
      "3\n",
      "Further Issues with Tokenization\n",
      "133\n",
      "2\n",
      "3.8  Segmentation\n",
      "134\n",
      "3\n",
      "Sentence Segmentation\n",
      "134\n",
      "3\n",
      "Word Segmentation\n",
      "135\n",
      "2\n",
      "3.9  Formatting: From Lists to Strings\n",
      "138\n",
      "3\n",
      "From Lists to Strings\n",
      "138\n",
      "3\n",
      "Strings and Formats\n",
      "139\n",
      "3\n",
      "Lining Things Up\n",
      "140\n",
      "3\n",
      "Writing Results to a File\n",
      "142\n",
      "3\n",
      "Text Wrapping\n",
      "142\n",
      "2\n",
      "3.10  Summary\n",
      "143\n",
      "2\n",
      "3.11  Further Reading\n",
      "144\n",
      "2\n",
      "3.12  Exercises\n",
      "145\n",
      "1\n",
      "Chapter 4. Writing Structured Programs\n",
      "151\n",
      "2\n",
      "4.1  Back to the Basics\n",
      "152\n",
      "3\n",
      "Assignment\n",
      "152\n",
      "3\n",
      "Equality\n",
      "154\n",
      "3\n",
      "Conditionals\n",
      "155\n",
      "2\n",
      "4.2  Sequences\n",
      "155\n",
      "3\n",
      "Operating on Sequence Types\n",
      "156\n",
      "3\n",
      "Combining Different Sequence Types\n",
      "158\n",
      "3\n",
      "Generator Expressions\n",
      "159\n",
      "2\n",
      "4.3  Questions of Style\n",
      "160\n",
      "3\n",
      "Python Coding Style\n",
      "160\n",
      "3\n",
      "Procedural Versus Declarative Style\n",
      "161\n",
      "3\n",
      "Some Legitimate Uses for Counters\n",
      "163\n",
      "2\n",
      "4.4  Functions: The Foundation of Structured Programming\n",
      "164\n",
      "3\n",
      "Function Inputs and Outputs\n",
      "165\n",
      "3\n",
      "Parameter Passing\n",
      "166\n",
      "3\n",
      "Variable Scope\n",
      "167\n",
      "3\n",
      "Checking Parameter Types\n",
      "168\n",
      "3\n",
      "Functional Decomposition\n",
      "169\n",
      "3\n",
      "Documenting Functions\n",
      "170\n",
      "2\n",
      "4.5  Doing More with Functions\n",
      "171\n",
      "3\n",
      "Functions As Arguments\n",
      "171\n",
      "3\n",
      "Accumulative Functions\n",
      "172\n",
      "3\n",
      "Higher-Order Functions\n",
      "173\n",
      "3\n",
      "Named Arguments\n",
      "174\n",
      "2\n",
      "4.6  Program Development\n",
      "176\n",
      "3\n",
      "Structure of a Python Module\n",
      "176\n",
      "3\n",
      "Multimodule Programs\n",
      "177\n",
      "3\n",
      "Sources of Error\n",
      "178\n",
      "3\n",
      "Debugging Techniques\n",
      "180\n",
      "3\n",
      "Defensive Programming\n",
      "181\n",
      "2\n",
      "4.7  Algorithm Design\n",
      "182\n",
      "3\n",
      "Recursion\n",
      "182\n",
      "3\n",
      "Space-Time Trade-offs\n",
      "185\n",
      "3\n",
      "Dynamic Programming\n",
      "187\n",
      "2\n",
      "4.8  A Sample of Python Libraries\n",
      "189\n",
      "3\n",
      "Matplotlib\n",
      "190\n",
      "3\n",
      "NetworkX\n",
      "191\n",
      "3\n",
      "csv\n",
      "192\n",
      "3\n",
      "NumPy\n",
      "193\n",
      "3\n",
      "Other Python Libraries\n",
      "194\n",
      "2\n",
      "4.9  Summary\n",
      "194\n",
      "2\n",
      "4.10  Further Reading\n",
      "195\n",
      "2\n",
      "4.11  Exercises\n",
      "195\n",
      "1\n",
      "Chapter 5. Categorizing and Tagging Words\n",
      "201\n",
      "2\n",
      "5.1  Using a Tagger\n",
      "201\n",
      "2\n",
      "5.2  Tagged Corpora\n",
      "203\n",
      "3\n",
      "Representing Tagged Tokens\n",
      "203\n",
      "3\n",
      "Reading Tagged Corpora\n",
      "203\n",
      "3\n",
      "A Simplified Part-of-Speech Tagset\n",
      "205\n",
      "3\n",
      "Nouns\n",
      "206\n",
      "3\n",
      "Verbs\n",
      "207\n",
      "3\n",
      "Adjectives and Adverbs\n",
      "208\n",
      "3\n",
      "Unsimplified Tags\n",
      "209\n",
      "3\n",
      "Exploring Tagged Corpora\n",
      "209\n",
      "2\n",
      "5.3  Mapping Words to Properties Using Python Dictionaries\n",
      "211\n",
      "3\n",
      "Indexing Lists Versus Dictionaries\n",
      "211\n",
      "3\n",
      "Dictionaries in Python\n",
      "212\n",
      "3\n",
      "Defining Dictionaries\n",
      "215\n",
      "3\n",
      "Default Dictionaries\n",
      "215\n",
      "3\n",
      "Incrementally Updating a Dictionary\n",
      "216\n",
      "3\n",
      "Complex Keys and Values\n",
      "218\n",
      "3\n",
      "Inverting a Dictionary\n",
      "219\n",
      "2\n",
      "5.4  Automatic Tagging\n",
      "220\n",
      "3\n",
      "The Default Tagger\n",
      "220\n",
      "3\n",
      "The Regular Expression Tagger\n",
      "221\n",
      "3\n",
      "The Lookup Tagger\n",
      "222\n",
      "3\n",
      "Evaluation\n",
      "223\n",
      "2\n",
      "5.5  N-Gram Tagging\n",
      "224\n",
      "3\n",
      "Unigram Tagging\n",
      "224\n",
      "3\n",
      "Separating the Training and Testing Data\n",
      "225\n",
      "3\n",
      "General N-Gram Tagging\n",
      "225\n",
      "3\n",
      "Combining Taggers\n",
      "227\n",
      "3\n",
      "Tagging Unknown Words\n",
      "228\n",
      "3\n",
      "Storing Taggers\n",
      "228\n",
      "3\n",
      "Performance Limitations\n",
      "228\n",
      "3\n",
      "Tagging Across Sentence Boundaries\n",
      "230\n",
      "2\n",
      "5.6  Transformation-Based Tagging\n",
      "230\n",
      "2\n",
      "5.7  How to Determine the Category of a Word\n",
      "232\n",
      "3\n",
      "Morphological Clues\n",
      "233\n",
      "3\n",
      "Syntactic Clues\n",
      "233\n",
      "3\n",
      "Semantic Clues\n",
      "233\n",
      "3\n",
      "New Words\n",
      "233\n",
      "3\n",
      "Morphology in Part-of-Speech Tagsets\n",
      "234\n",
      "2\n",
      "5.8  Summary\n",
      "235\n",
      "2\n",
      "5.9  Further Reading\n",
      "236\n",
      "2\n",
      "5.10  Exercises\n",
      "237\n",
      "1\n",
      "Chapter 6. Learning to Classify Text\n",
      "243\n",
      "2\n",
      "6.1  Supervised Classification\n",
      "243\n",
      "3\n",
      "Gender Identification\n",
      "244\n",
      "3\n",
      "Choosing the Right Features\n",
      "246\n",
      "3\n",
      "Document Classification\n",
      "249\n",
      "3\n",
      "Part-of-Speech Tagging\n",
      "251\n",
      "3\n",
      "Exploiting Context\n",
      "252\n",
      "3\n",
      "Sequence Classification\n",
      "253\n",
      "3\n",
      "Other Methods for Sequence Classification\n",
      "255\n",
      "2\n",
      "6.2  Further Examples of Supervised Classification\n",
      "255\n",
      "3\n",
      "Sentence Segmentation\n",
      "255\n",
      "3\n",
      "Identifying Dialogue Act Types\n",
      "257\n",
      "3\n",
      "Recognizing Textual Entailment\n",
      "257\n",
      "3\n",
      "Scaling Up to Large Datasets\n",
      "259\n",
      "2\n",
      "6.3  Evaluation\n",
      "259\n",
      "3\n",
      "The Test Set\n",
      "259\n",
      "3\n",
      "Accuracy\n",
      "261\n",
      "3\n",
      "Precision and Recall\n",
      "261\n",
      "3\n",
      "Confusion Matrices\n",
      "262\n",
      "3\n",
      "Cross-Validation\n",
      "263\n",
      "2\n",
      "6.4  Decision Trees\n",
      "264\n",
      "3\n",
      "Entropy and Information Gain\n",
      "265\n",
      "2\n",
      "6.5  Naive Bayes Classifiers\n",
      "267\n",
      "3\n",
      "Underlying Probabilistic Model\n",
      "269\n",
      "3\n",
      "Zero Counts and Smoothing\n",
      "270\n",
      "3\n",
      "Non-Binary Features\n",
      "271\n",
      "3\n",
      "The Naivete of Independence\n",
      "271\n",
      "3\n",
      "The Cause of Double-Counting\n",
      "272\n",
      "2\n",
      "6.6  Maximum Entropy Classifiers\n",
      "272\n",
      "3\n",
      "The Maximum Entropy Model\n",
      "273\n",
      "3\n",
      "Maximizing Entropy\n",
      "274\n",
      "3\n",
      "Generative Versus Conditional Classifiers\n",
      "276\n",
      "2\n",
      "6.7  Modeling Linguistic Patterns\n",
      "276\n",
      "3\n",
      "What Do Models Tell Us?\n",
      "277\n",
      "2\n",
      "6.8  Summary\n",
      "278\n",
      "2\n",
      "6.9  Further Reading\n",
      "278\n",
      "2\n",
      "6.10  Exercises\n",
      "279\n",
      "1\n",
      "Chapter 7. Extracting Information from Text\n",
      "283\n",
      "2\n",
      "7.1  Information Extraction\n",
      "283\n",
      "3\n",
      "Information Extraction Architecture\n",
      "285\n",
      "2\n",
      "7.2  Chunking\n",
      "286\n",
      "3\n",
      "Noun Phrase Chunking\n",
      "286\n",
      "3\n",
      "Tag Patterns\n",
      "288\n",
      "3\n",
      "Chunking with Regular Expressions\n",
      "288\n",
      "3\n",
      "Exploring Text Corpora\n",
      "289\n",
      "3\n",
      "Chinking\n",
      "290\n",
      "3\n",
      "Representing Chunks: Tags Versus Trees\n",
      "291\n",
      "2\n",
      "7.3  Developing and Evaluating Chunkers\n",
      "292\n",
      "3\n",
      "Reading IOB Format and the CoNLL-2000 Chunking Corpus\n",
      "292\n",
      "3\n",
      "Simple Evaluation and Baselines\n",
      "294\n",
      "3\n",
      "Training Classifier-Based Chunkers\n",
      "296\n",
      "2\n",
      "7.4  Recursion in Linguistic Structure\n",
      "299\n",
      "3\n",
      "Building Nested Structure with Cascaded Chunkers\n",
      "299\n",
      "3\n",
      "Trees\n",
      "301\n",
      "3\n",
      "Tree Traversal\n",
      "302\n",
      "2\n",
      "7.5  Named Entity Recognition\n",
      "303\n",
      "2\n",
      "7.6  Relation Extraction\n",
      "306\n",
      "2\n",
      "7.7  Summary\n",
      "307\n",
      "2\n",
      "7.8  Further Reading\n",
      "308\n",
      "2\n",
      "7.9  Exercises\n",
      "308\n",
      "1\n",
      "Chapter 8. Analyzing Sentence Structure\n",
      "313\n",
      "2\n",
      "8.1  Some Grammatical Dilemmas\n",
      "314\n",
      "3\n",
      "Linguistic Data and Unlimited Possibilities\n",
      "314\n",
      "3\n",
      "Ubiquitous Ambiguity\n",
      "315\n",
      "2\n",
      "8.2  What’s the Use of Syntax?\n",
      "317\n",
      "3\n",
      "Beyond n-grams\n",
      "317\n",
      "2\n",
      "8.3  Context-Free Grammar\n",
      "320\n",
      "3\n",
      "A Simple Grammar\n",
      "320\n",
      "3\n",
      "Writing Your Own Grammars\n",
      "322\n",
      "3\n",
      "Recursion in Syntactic Structure\n",
      "323\n",
      "2\n",
      "8.4  Parsing with Context-Free Grammar\n",
      "324\n",
      "3\n",
      "Recursive Descent Parsing\n",
      "325\n",
      "3\n",
      "Shift-Reduce Parsing\n",
      "326\n",
      "3\n",
      "The Left-Corner Parser\n",
      "328\n",
      "3\n",
      "Well-Formed Substring Tables\n",
      "329\n",
      "2\n",
      "8.5  Dependencies and Dependency Grammar\n",
      "332\n",
      "3\n",
      "Valency and the Lexicon\n",
      "334\n",
      "3\n",
      "Scaling Up\n",
      "336\n",
      "2\n",
      "8.6  Grammar Development\n",
      "337\n",
      "3\n",
      "Treebanks and Grammars\n",
      "337\n",
      "3\n",
      "Pernicious Ambiguity\n",
      "339\n",
      "3\n",
      "Weighted Grammar\n",
      "340\n",
      "2\n",
      "8.7  Summary\n",
      "343\n",
      "2\n",
      "8.8  Further Reading\n",
      "344\n",
      "2\n",
      "8.9  Exercises\n",
      "344\n",
      "1\n",
      "Chapter 9. Building Feature-Based Grammars\n",
      "349\n",
      "2\n",
      "9.1  Grammatical Features\n",
      "349\n",
      "3\n",
      "Syntactic Agreement\n",
      "351\n",
      "3\n",
      "Using Attributes and Constraints\n",
      "353\n",
      "3\n",
      "Terminology\n",
      "357\n",
      "2\n",
      "9.2  Processing Feature Structures\n",
      "359\n",
      "3\n",
      "Subsumption and Unification\n",
      "363\n",
      "2\n",
      "9.3  Extending a Feature-Based Grammar\n",
      "366\n",
      "3\n",
      "Subcategorization\n",
      "366\n",
      "3\n",
      "Heads Revisited\n",
      "369\n",
      "3\n",
      "Auxiliary Verbs and Inversion\n",
      "370\n",
      "3\n",
      "Unbounded Dependency Constructions\n",
      "371\n",
      "3\n",
      "Case and Gender in German\n",
      "375\n",
      "2\n",
      "9.4  Summary\n",
      "378\n",
      "2\n",
      "9.5  Further Reading\n",
      "379\n",
      "2\n",
      "9.6  Exercises\n",
      "380\n",
      "1\n",
      "Chapter 10. Analyzing the Meaning of Sentences\n",
      "383\n",
      "2\n",
      "10.1  Natural Language Understanding\n",
      "383\n",
      "3\n",
      "Querying a Database\n",
      "383\n",
      "3\n",
      "Natural Language, Semantics, and Logic\n",
      "387\n",
      "2\n",
      "10.2  Propositional Logic\n",
      "390\n",
      "2\n",
      "10.3  First-Order Logic\n",
      "394\n",
      "3\n",
      "Syntax\n",
      "394\n",
      "3\n",
      "First-Order Theorem Proving\n",
      "397\n",
      "3\n",
      "Summarizing the Language of First-Order Logic\n",
      "398\n",
      "3\n",
      "Truth in Model\n",
      "399\n",
      "3\n",
      "Individual Variables and Assignments\n",
      "400\n",
      "3\n",
      "Quantification\n",
      "402\n",
      "3\n",
      "Quantifier Scope Ambiguity\n",
      "403\n",
      "3\n",
      "Model Building\n",
      "405\n",
      "2\n",
      "10.4  The Semantics of English Sentences\n",
      "407\n",
      "3\n",
      "Compositional Semantics in Feature-Based Grammar\n",
      "407\n",
      "3\n",
      "The λ-Calculus\n",
      "408\n",
      "3\n",
      "Quantified NPs\n",
      "412\n",
      "3\n",
      "Transitive Verbs\n",
      "413\n",
      "3\n",
      "Quantifier Ambiguity Revisited\n",
      "416\n",
      "2\n",
      "10.5  Discourse Semantics\n",
      "419\n",
      "3\n",
      "Discourse Representation Theory\n",
      "419\n",
      "3\n",
      "Discourse Processing\n",
      "422\n",
      "2\n",
      "10.6  Summary\n",
      "424\n",
      "2\n",
      "10.7  Further Reading\n",
      "425\n",
      "2\n",
      "10.8  Exercises\n",
      "426\n",
      "1\n",
      "Chapter 11. Managing Linguistic Data\n",
      "429\n",
      "2\n",
      "11.1  Corpus Structure: A Case Study\n",
      "429\n",
      "3\n",
      "The Structure of TIMIT\n",
      "429\n",
      "3\n",
      "Notable Design Features\n",
      "431\n",
      "3\n",
      "Fundamental Data Types\n",
      "433\n",
      "2\n",
      "11.2  The Life Cycle of a Corpus\n",
      "434\n",
      "3\n",
      "Three Corpus Creation Scenarios\n",
      "434\n",
      "3\n",
      "Quality Control\n",
      "435\n",
      "3\n",
      "Curation Versus Evolution\n",
      "436\n",
      "2\n",
      "11.3  Acquiring Data\n",
      "438\n",
      "3\n",
      "Obtaining Data from the Web\n",
      "438\n",
      "3\n",
      "Obtaining Data from Word Processor Files\n",
      "438\n",
      "3\n",
      "Obtaining Data from Spreadsheets and Databases\n",
      "440\n",
      "3\n",
      "Converting Data Formats\n",
      "441\n",
      "3\n",
      "Deciding Which Layers of Annotation to Include\n",
      "442\n",
      "3\n",
      "Standards and Tools\n",
      "443\n",
      "3\n",
      "Special Considerations When Working with Endangered Languages\n",
      "444\n",
      "2\n",
      "11.4  Working with XML\n",
      "447\n",
      "3\n",
      "Using XML for Linguistic Structures\n",
      "447\n",
      "3\n",
      "The Role of XML\n",
      "448\n",
      "3\n",
      "The ElementTree Interface\n",
      "449\n",
      "3\n",
      "Using ElementTree for Accessing Toolbox Data\n",
      "451\n",
      "3\n",
      "Formatting Entries\n",
      "452\n",
      "2\n",
      "11.5  Working with Toolbox Data\n",
      "453\n",
      "3\n",
      "Adding a Field to Each Entry\n",
      "453\n",
      "3\n",
      "Validating a Toolbox Lexicon\n",
      "454\n",
      "2\n",
      "11.6  Describing Language Resources Using OLAC Metadata\n",
      "457\n",
      "3\n",
      "What Is Metadata?\n",
      "457\n",
      "3\n",
      "OLAC: Open Language Archives Community\n",
      "457\n",
      "2\n",
      "11.7  Summary\n",
      "459\n",
      "2\n",
      "11.8  Further Reading\n",
      "459\n",
      "2\n",
      "11.9  Exercises\n",
      "460\n",
      "1\n",
      "Afterword: The Language Challenge\n",
      "463\n",
      "2\n",
      "Language Processing Versus Symbol Processing\n",
      "464\n",
      "2\n",
      "Contemporary Philosophical Divides\n",
      "465\n",
      "2\n",
      "NLTK Roadmap\n",
      "466\n",
      "2\n",
      "Envoi...\n",
      "469\n",
      "1\n",
      "Bibliography\n",
      "471\n",
      "1\n",
      "NLTK Index\n",
      "481\n",
      "1\n",
      "General Index\n",
      "485\n"
     ]
    }
   ],
   "source": [
    "d={}\n",
    "for i in toc:\n",
    "    for j in i:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "7\n",
      "Preface\n",
      "11\n",
      "Audience\n",
      "12\n",
      "Emphasis\n",
      "12\n",
      "What You Will Learn\n",
      "13\n",
      "Organization\n",
      "13\n",
      "Why Python?\n",
      "14\n",
      "Software Requirements\n",
      "15\n",
      "Natural Language Toolkit (NLTK)\n",
      "16\n",
      "For Instructors\n",
      "17\n",
      "Conventions Used in This Book\n",
      "19\n",
      "Using Code Examples\n",
      "19\n",
      "Safari® Books Online\n",
      "20\n",
      "How to Contact Us\n",
      "20\n",
      "Acknowledgments\n",
      "21\n",
      "Royalties\n",
      "21\n",
      "Chapter 1. Language Processing and Python\n",
      "23\n",
      "1.1  Computing with Language: Texts and Words\n",
      "23\n",
      "Getting Started with Python\n",
      "24\n",
      "Getting Started with NLTK\n",
      "25\n",
      "Searching Text\n",
      "26\n",
      "Counting Vocabulary\n",
      "29\n",
      "1.2  A Closer Look at Python: Texts as Lists of Words\n",
      "32\n",
      "Lists\n",
      "32\n",
      "Indexing Lists\n",
      "34\n",
      "Variables\n",
      "36\n",
      "Strings\n",
      "37\n",
      "1.3  Computing with Language: Simple Statistics\n",
      "38\n",
      "Frequency Distributions\n",
      "39\n",
      "Fine-Grained Selection of Words\n",
      "41\n",
      "Collocations and Bigrams\n",
      "42\n",
      "Counting Other Things\n",
      "43\n",
      "1.4  Back to Python: Making Decisions and Taking Control\n",
      "44\n",
      "Conditionals\n",
      "44\n",
      "Operating on Every Element\n",
      "46\n",
      "Nested Code Blocks\n",
      "47\n",
      "Looping with Conditions\n",
      "48\n",
      "1.5  Automatic Natural Language Understanding\n",
      "49\n",
      "Word Sense Disambiguation\n",
      "50\n",
      "Pronoun Resolution\n",
      "50\n",
      "Generating Language Output\n",
      "51\n",
      "Machine Translation\n",
      "51\n",
      "Spoken Dialogue Systems\n",
      "53\n",
      "Textual Entailment\n",
      "54\n",
      "Limitations of NLP\n",
      "55\n",
      "1.6  Summary\n",
      "55\n",
      "1.7  Further Reading\n",
      "56\n",
      "1.8  Exercises\n",
      "57\n",
      "Chapter 2. Accessing Text Corpora and Lexical\n",
      "  Resources\n",
      "61\n",
      "2.1  Accessing Text Corpora\n",
      "61\n",
      "Gutenberg Corpus\n",
      "62\n",
      "Web and Chat Text\n",
      "64\n",
      "Brown Corpus\n",
      "64\n",
      "Reuters Corpus\n",
      "66\n",
      "Inaugural Address Corpus\n",
      "67\n",
      "Annotated Text Corpora\n",
      "68\n",
      "Corpora in Other Languages\n",
      "70\n",
      "Text Corpus Structure\n",
      "71\n",
      "Loading Your Own Corpus\n",
      "73\n",
      "2.2  Conditional Frequency Distributions\n",
      "74\n",
      "Conditions and Events\n",
      "74\n",
      "Counting Words by Genre\n",
      "74\n",
      "Plotting and Tabulating Distributions\n",
      "75\n",
      "Generating Random Text with Bigrams\n",
      "77\n",
      "2.3  More Python: Reusing Code\n",
      "78\n",
      "Creating Programs with a Text Editor\n",
      "78\n",
      "Functions\n",
      "79\n",
      "Modules\n",
      "81\n",
      "2.4  Lexical Resources\n",
      "81\n",
      "Wordlist Corpora\n",
      "82\n",
      "A Pronouncing Dictionary\n",
      "85\n",
      "Comparative Wordlists\n",
      "87\n",
      "Shoebox and Toolbox Lexicons\n",
      "88\n",
      "2.5  WordNet\n",
      "89\n",
      "Senses and Synonyms\n",
      "89\n",
      "The WordNet Hierarchy\n",
      "91\n",
      "More Lexical Relations\n",
      "92\n",
      "Semantic Similarity\n",
      "93\n",
      "2.6  Summary\n",
      "95\n",
      "2.7  Further Reading\n",
      "95\n",
      "2.8  Exercises\n",
      "96\n",
      "Chapter 3. Processing Raw Text\n",
      "101\n",
      "3.1  Accessing Text from the Web and from Disk\n",
      "102\n",
      "Electronic Books\n",
      "102\n",
      "Dealing with HTML\n",
      "103\n",
      "Processing Search Engine Results\n",
      "104\n",
      "Processing RSS Feeds\n",
      "105\n",
      "Reading Local Files\n",
      "106\n",
      "Extracting Text from PDF, MSWord, and Other Binary Formats\n",
      "107\n",
      "Capturing User Input\n",
      "107\n",
      "The NLP Pipeline\n",
      "108\n",
      "3.2  Strings: Text Processing at the Lowest Level\n",
      "109\n",
      "Basic Operations with Strings\n",
      "109\n",
      "Printing Strings\n",
      "111\n",
      "Accessing Individual Characters\n",
      "111\n",
      "Accessing Substrings\n",
      "112\n",
      "More Operations on Strings\n",
      "114\n",
      "The Difference Between Lists and Strings\n",
      "114\n",
      "3.3  Text Processing with Unicode\n",
      "115\n",
      "What Is Unicode?\n",
      "116\n",
      "Extracting Encoded Text from Files\n",
      "116\n",
      "Using Your Local Encoding in Python\n",
      "119\n",
      "3.4  Regular Expressions for Detecting Word Patterns\n",
      "119\n",
      "Using Basic Metacharacters\n",
      "120\n",
      "Ranges and Closures\n",
      "121\n",
      "3.5  Useful Applications of Regular Expressions\n",
      "124\n",
      "Extracting Word Pieces\n",
      "124\n",
      "Doing More with Word Pieces\n",
      "124\n",
      "Finding Word Stems\n",
      "126\n",
      "Searching Tokenized Text\n",
      "127\n",
      "3.6  Normalizing Text\n",
      "129\n",
      "Stemmers\n",
      "129\n",
      "Lemmatization\n",
      "130\n",
      "3.7  Regular Expressions for Tokenizing Text\n",
      "131\n",
      "Simple Approaches to Tokenization\n",
      "131\n",
      "NLTK’s Regular Expression Tokenizer\n",
      "133\n",
      "Further Issues with Tokenization\n",
      "133\n",
      "3.8  Segmentation\n",
      "134\n",
      "Sentence Segmentation\n",
      "134\n",
      "Word Segmentation\n",
      "135\n",
      "3.9  Formatting: From Lists to Strings\n",
      "138\n",
      "From Lists to Strings\n",
      "138\n",
      "Strings and Formats\n",
      "139\n",
      "Lining Things Up\n",
      "140\n",
      "Writing Results to a File\n",
      "142\n",
      "Text Wrapping\n",
      "142\n",
      "3.10  Summary\n",
      "143\n",
      "3.11  Further Reading\n",
      "144\n",
      "3.12  Exercises\n",
      "145\n",
      "Chapter 4. Writing Structured Programs\n",
      "151\n",
      "4.1  Back to the Basics\n",
      "152\n",
      "Assignment\n",
      "152\n",
      "Equality\n",
      "154\n",
      "Conditionals\n",
      "155\n",
      "4.2  Sequences\n",
      "155\n",
      "Operating on Sequence Types\n",
      "156\n",
      "Combining Different Sequence Types\n",
      "158\n",
      "Generator Expressions\n",
      "159\n",
      "4.3  Questions of Style\n",
      "160\n",
      "Python Coding Style\n",
      "160\n",
      "Procedural Versus Declarative Style\n",
      "161\n",
      "Some Legitimate Uses for Counters\n",
      "163\n",
      "4.4  Functions: The Foundation of Structured Programming\n",
      "164\n",
      "Function Inputs and Outputs\n",
      "165\n",
      "Parameter Passing\n",
      "166\n",
      "Variable Scope\n",
      "167\n",
      "Checking Parameter Types\n",
      "168\n",
      "Functional Decomposition\n",
      "169\n",
      "Documenting Functions\n",
      "170\n",
      "4.5  Doing More with Functions\n",
      "171\n",
      "Functions As Arguments\n",
      "171\n",
      "Accumulative Functions\n",
      "172\n",
      "Higher-Order Functions\n",
      "173\n",
      "Named Arguments\n",
      "174\n",
      "4.6  Program Development\n",
      "176\n",
      "Structure of a Python Module\n",
      "176\n",
      "Multimodule Programs\n",
      "177\n",
      "Sources of Error\n",
      "178\n",
      "Debugging Techniques\n",
      "180\n",
      "Defensive Programming\n",
      "181\n",
      "4.7  Algorithm Design\n",
      "182\n",
      "Recursion\n",
      "182\n",
      "Space-Time Trade-offs\n",
      "185\n",
      "Dynamic Programming\n",
      "187\n",
      "4.8  A Sample of Python Libraries\n",
      "189\n",
      "Matplotlib\n",
      "190\n",
      "NetworkX\n",
      "191\n",
      "csv\n",
      "192\n",
      "NumPy\n",
      "193\n",
      "Other Python Libraries\n",
      "194\n",
      "4.9  Summary\n",
      "194\n",
      "4.10  Further Reading\n",
      "195\n",
      "4.11  Exercises\n",
      "195\n",
      "Chapter 5. Categorizing and Tagging Words\n",
      "201\n",
      "5.1  Using a Tagger\n",
      "201\n",
      "5.2  Tagged Corpora\n",
      "203\n",
      "Representing Tagged Tokens\n",
      "203\n",
      "Reading Tagged Corpora\n",
      "203\n",
      "A Simplified Part-of-Speech Tagset\n",
      "205\n",
      "Nouns\n",
      "206\n",
      "Verbs\n",
      "207\n",
      "Adjectives and Adverbs\n",
      "208\n",
      "Unsimplified Tags\n",
      "209\n",
      "Exploring Tagged Corpora\n",
      "209\n",
      "5.3  Mapping Words to Properties Using Python Dictionaries\n",
      "211\n",
      "Indexing Lists Versus Dictionaries\n",
      "211\n",
      "Dictionaries in Python\n",
      "212\n",
      "Defining Dictionaries\n",
      "215\n",
      "Default Dictionaries\n",
      "215\n",
      "Incrementally Updating a Dictionary\n",
      "216\n",
      "Complex Keys and Values\n",
      "218\n",
      "Inverting a Dictionary\n",
      "219\n",
      "5.4  Automatic Tagging\n",
      "220\n",
      "The Default Tagger\n",
      "220\n",
      "The Regular Expression Tagger\n",
      "221\n",
      "The Lookup Tagger\n",
      "222\n",
      "Evaluation\n",
      "223\n",
      "5.5  N-Gram Tagging\n",
      "224\n",
      "Unigram Tagging\n",
      "224\n",
      "Separating the Training and Testing Data\n",
      "225\n",
      "General N-Gram Tagging\n",
      "225\n",
      "Combining Taggers\n",
      "227\n",
      "Tagging Unknown Words\n",
      "228\n",
      "Storing Taggers\n",
      "228\n",
      "Performance Limitations\n",
      "228\n",
      "Tagging Across Sentence Boundaries\n",
      "230\n",
      "5.6  Transformation-Based Tagging\n",
      "230\n",
      "5.7  How to Determine the Category of a Word\n",
      "232\n",
      "Morphological Clues\n",
      "233\n",
      "Syntactic Clues\n",
      "233\n",
      "Semantic Clues\n",
      "233\n",
      "New Words\n",
      "233\n",
      "Morphology in Part-of-Speech Tagsets\n",
      "234\n",
      "5.8  Summary\n",
      "235\n",
      "5.9  Further Reading\n",
      "236\n",
      "5.10  Exercises\n",
      "237\n",
      "Chapter 6. Learning to Classify Text\n",
      "243\n",
      "6.1  Supervised Classification\n",
      "243\n",
      "Gender Identification\n",
      "244\n",
      "Choosing the Right Features\n",
      "246\n",
      "Document Classification\n",
      "249\n",
      "Part-of-Speech Tagging\n",
      "251\n",
      "Exploiting Context\n",
      "252\n",
      "Sequence Classification\n",
      "253\n",
      "Other Methods for Sequence Classification\n",
      "255\n",
      "6.2  Further Examples of Supervised Classification\n",
      "255\n",
      "Sentence Segmentation\n",
      "255\n",
      "Identifying Dialogue Act Types\n",
      "257\n",
      "Recognizing Textual Entailment\n",
      "257\n",
      "Scaling Up to Large Datasets\n",
      "259\n",
      "6.3  Evaluation\n",
      "259\n",
      "The Test Set\n",
      "259\n",
      "Accuracy\n",
      "261\n",
      "Precision and Recall\n",
      "261\n",
      "Confusion Matrices\n",
      "262\n",
      "Cross-Validation\n",
      "263\n",
      "6.4  Decision Trees\n",
      "264\n",
      "Entropy and Information Gain\n",
      "265\n",
      "6.5  Naive Bayes Classifiers\n",
      "267\n",
      "Underlying Probabilistic Model\n",
      "269\n",
      "Zero Counts and Smoothing\n",
      "270\n",
      "Non-Binary Features\n",
      "271\n",
      "The Naivete of Independence\n",
      "271\n",
      "The Cause of Double-Counting\n",
      "272\n",
      "6.6  Maximum Entropy Classifiers\n",
      "272\n",
      "The Maximum Entropy Model\n",
      "273\n",
      "Maximizing Entropy\n",
      "274\n",
      "Generative Versus Conditional Classifiers\n",
      "276\n",
      "6.7  Modeling Linguistic Patterns\n",
      "276\n",
      "What Do Models Tell Us?\n",
      "277\n",
      "6.8  Summary\n",
      "278\n",
      "6.9  Further Reading\n",
      "278\n",
      "6.10  Exercises\n",
      "279\n",
      "Chapter 7. Extracting Information from Text\n",
      "283\n",
      "7.1  Information Extraction\n",
      "283\n",
      "Information Extraction Architecture\n",
      "285\n",
      "7.2  Chunking\n",
      "286\n",
      "Noun Phrase Chunking\n",
      "286\n",
      "Tag Patterns\n",
      "288\n",
      "Chunking with Regular Expressions\n",
      "288\n",
      "Exploring Text Corpora\n",
      "289\n",
      "Chinking\n",
      "290\n",
      "Representing Chunks: Tags Versus Trees\n",
      "291\n",
      "7.3  Developing and Evaluating Chunkers\n",
      "292\n",
      "Reading IOB Format and the CoNLL-2000 Chunking Corpus\n",
      "292\n",
      "Simple Evaluation and Baselines\n",
      "294\n",
      "Training Classifier-Based Chunkers\n",
      "296\n",
      "7.4  Recursion in Linguistic Structure\n",
      "299\n",
      "Building Nested Structure with Cascaded Chunkers\n",
      "299\n",
      "Trees\n",
      "301\n",
      "Tree Traversal\n",
      "302\n",
      "7.5  Named Entity Recognition\n",
      "303\n",
      "7.6  Relation Extraction\n",
      "306\n",
      "7.7  Summary\n",
      "307\n",
      "7.8  Further Reading\n",
      "308\n",
      "7.9  Exercises\n",
      "308\n",
      "Chapter 8. Analyzing Sentence Structure\n",
      "313\n",
      "8.1  Some Grammatical Dilemmas\n",
      "314\n",
      "Linguistic Data and Unlimited Possibilities\n",
      "314\n",
      "Ubiquitous Ambiguity\n",
      "315\n",
      "8.2  What’s the Use of Syntax?\n",
      "317\n",
      "Beyond n-grams\n",
      "317\n",
      "8.3  Context-Free Grammar\n",
      "320\n",
      "A Simple Grammar\n",
      "320\n",
      "Writing Your Own Grammars\n",
      "322\n",
      "Recursion in Syntactic Structure\n",
      "323\n",
      "8.4  Parsing with Context-Free Grammar\n",
      "324\n",
      "Recursive Descent Parsing\n",
      "325\n",
      "Shift-Reduce Parsing\n",
      "326\n",
      "The Left-Corner Parser\n",
      "328\n",
      "Well-Formed Substring Tables\n",
      "329\n",
      "8.5  Dependencies and Dependency Grammar\n",
      "332\n",
      "Valency and the Lexicon\n",
      "334\n",
      "Scaling Up\n",
      "336\n",
      "8.6  Grammar Development\n",
      "337\n",
      "Treebanks and Grammars\n",
      "337\n",
      "Pernicious Ambiguity\n",
      "339\n",
      "Weighted Grammar\n",
      "340\n",
      "8.7  Summary\n",
      "343\n",
      "8.8  Further Reading\n",
      "344\n",
      "8.9  Exercises\n",
      "344\n",
      "Chapter 9. Building Feature-Based Grammars\n",
      "349\n",
      "9.1  Grammatical Features\n",
      "349\n",
      "Syntactic Agreement\n",
      "351\n",
      "Using Attributes and Constraints\n",
      "353\n",
      "Terminology\n",
      "357\n",
      "9.2  Processing Feature Structures\n",
      "359\n",
      "Subsumption and Unification\n",
      "363\n",
      "9.3  Extending a Feature-Based Grammar\n",
      "366\n",
      "Subcategorization\n",
      "366\n",
      "Heads Revisited\n",
      "369\n",
      "Auxiliary Verbs and Inversion\n",
      "370\n",
      "Unbounded Dependency Constructions\n",
      "371\n",
      "Case and Gender in German\n",
      "375\n",
      "9.4  Summary\n",
      "378\n",
      "9.5  Further Reading\n",
      "379\n",
      "9.6  Exercises\n",
      "380\n",
      "Chapter 10. Analyzing the Meaning of Sentences\n",
      "383\n",
      "10.1  Natural Language Understanding\n",
      "383\n",
      "Querying a Database\n",
      "383\n",
      "Natural Language, Semantics, and Logic\n",
      "387\n",
      "10.2  Propositional Logic\n",
      "390\n",
      "10.3  First-Order Logic\n",
      "394\n",
      "Syntax\n",
      "394\n",
      "First-Order Theorem Proving\n",
      "397\n",
      "Summarizing the Language of First-Order Logic\n",
      "398\n",
      "Truth in Model\n",
      "399\n",
      "Individual Variables and Assignments\n",
      "400\n",
      "Quantification\n",
      "402\n",
      "Quantifier Scope Ambiguity\n",
      "403\n",
      "Model Building\n",
      "405\n",
      "10.4  The Semantics of English Sentences\n",
      "407\n",
      "Compositional Semantics in Feature-Based Grammar\n",
      "407\n",
      "The λ-Calculus\n",
      "408\n",
      "Quantified NPs\n",
      "412\n",
      "Transitive Verbs\n",
      "413\n",
      "Quantifier Ambiguity Revisited\n",
      "416\n",
      "10.5  Discourse Semantics\n",
      "419\n",
      "Discourse Representation Theory\n",
      "419\n",
      "Discourse Processing\n",
      "422\n",
      "10.6  Summary\n",
      "424\n",
      "10.7  Further Reading\n",
      "425\n",
      "10.8  Exercises\n",
      "426\n",
      "Chapter 11. Managing Linguistic Data\n",
      "429\n",
      "11.1  Corpus Structure: A Case Study\n",
      "429\n",
      "The Structure of TIMIT\n",
      "429\n",
      "Notable Design Features\n",
      "431\n",
      "Fundamental Data Types\n",
      "433\n",
      "11.2  The Life Cycle of a Corpus\n",
      "434\n",
      "Three Corpus Creation Scenarios\n",
      "434\n",
      "Quality Control\n",
      "435\n",
      "Curation Versus Evolution\n",
      "436\n",
      "11.3  Acquiring Data\n",
      "438\n",
      "Obtaining Data from the Web\n",
      "438\n",
      "Obtaining Data from Word Processor Files\n",
      "438\n",
      "Obtaining Data from Spreadsheets and Databases\n",
      "440\n",
      "Converting Data Formats\n",
      "441\n",
      "Deciding Which Layers of Annotation to Include\n",
      "442\n",
      "Standards and Tools\n",
      "443\n",
      "Special Considerations When Working with Endangered Languages\n",
      "444\n",
      "11.4  Working with XML\n",
      "447\n",
      "Using XML for Linguistic Structures\n",
      "447\n",
      "The Role of XML\n",
      "448\n",
      "The ElementTree Interface\n",
      "449\n",
      "Using ElementTree for Accessing Toolbox Data\n",
      "451\n",
      "Formatting Entries\n",
      "452\n",
      "11.5  Working with Toolbox Data\n",
      "453\n",
      "Adding a Field to Each Entry\n",
      "453\n",
      "Validating a Toolbox Lexicon\n",
      "454\n",
      "11.6  Describing Language Resources Using OLAC Metadata\n",
      "457\n",
      "What Is Metadata?\n",
      "457\n",
      "OLAC: Open Language Archives Community\n",
      "457\n",
      "11.7  Summary\n",
      "459\n",
      "11.8  Further Reading\n",
      "459\n",
      "11.9  Exercises\n",
      "460\n",
      "Afterword: The Language Challenge\n",
      "463\n",
      "Language Processing Versus Symbol Processing\n",
      "464\n",
      "Contemporary Philosophical Divides\n",
      "465\n",
      "NLTK Roadmap\n",
      "466\n",
      "Envoi...\n",
      "469\n",
      "Bibliography\n",
      "471\n",
      "NLTK Index\n",
      "481\n",
      "General Index\n",
      "485\n"
     ]
    }
   ],
   "source": [
    "for i in toc:\n",
    "    d={}\n",
    "    d[\"title\"]=i[1]\n",
    "    d[\"Pgno\"]=i[2]\n",
    "    print(i[1])\n",
    "    print(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(toc[0][1])\n",
    "print(toc[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
